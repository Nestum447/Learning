import streamlit as st
import numpy as np
import time

st.set_page_config(page_title="Aprendizaje por Recompensa", layout="centered")

st.title("ğŸ¤– Aprendizaje por Recompensa (Q-Learning)")
st.markdown("El agente aprende a llegar a la meta ğŸ† moviÃ©ndose en una lÃ­nea de 5 posiciones mediante **prueba y error**.")

# --- ParÃ¡metros ---
states = [0, 1, 2, 3, 4]
actions = [0, 1]  # 0=izquierda, 1=derecha
goal_state = 4

alpha = st.sidebar.slider("Tasa de aprendizaje (Î±)", 0.0, 1.0, 0.1, 0.05)
gamma = st.sidebar.slider("Factor de descuento (Î³)", 0.0, 1.0, 0.9, 0.05)
epsilon = st.sidebar.slider("ExploraciÃ³n (Îµ)", 0.0, 1.0, 0.2, 0.05)
episodes = st.sidebar.slider("NÃºmero de episodios", 5, 100, 20, 5)

# --- Inicializamos la tabla Q ---
Q = np.zeros((len(states), len(actions)))

# --- FunciÃ³n de recompensa ---
def get_reward(state):
    return 10 if state == goal_state else -1

# --- FunciÃ³n para mostrar entorno ---
def show_environment(state):
    cells = ["â¬œ"] * len(states)
    cells[state] = "ğŸ¤–"
    cells[goal_state] = "ğŸ†"
    st.markdown(" ".join(cells))

# --- Entrenamiento ---
start = st.button("ğŸš€ Iniciar entrenamiento")

if start:
    progress = st.progress(0)
    for episode in range(episodes):
        state = 0
        done = False
        step = 0

        st.subheader(f"Episodio {episode+1}")
        placeholder = st.empty()

        while not done:
            with placeholder.container():
                show_environment(state)
                st.write(f"â¡ï¸ Estado: {state} | Paso: {step}")

            # Elegir acciÃ³n (explorar o explotar)
            if np.random.rand() < epsilon:
                action = np.random.choice(actions)
            else:
                action = np.argmax(Q[state])

            # Ejecutar acciÃ³n
            if action == 0:
                next_state = max(0, state - 1)
            else:
                next_state = min(goal_state, state + 1)

            reward = get_reward(next_state)

            # Actualizar Q-table
            Q[state, action] = Q[state, action] + alpha * (
                reward + gamma * np.max(Q[next_state]) - Q[state, action]
            )

            state = next_state
            step += 1

            if state == goal_state:
                done = True
                with placeholder.container():
                    show_environment(state)
                    st.success(f"ğŸ‰ Â¡Meta alcanzada en {step} pasos!")
                time.sleep(0.5)
            else:
                time.sleep(0.2)

        progress.progress((episode + 1) / episodes)
        time.sleep(0.2)

    st.subheader("ğŸ“Š Tabla Q aprendida:")
    st.dataframe(Q, use_container_width=True)
    st.success("Entrenamiento completado âœ…")
